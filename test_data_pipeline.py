#!/usr/bin/env python3
"""
Test script to verify the data pipeline is working correctly.
Run this after applying fixes to see what's actually being stored.
"""

import os
import sys
import json

# Add the project root to path
ROOT = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, ROOT)

from core.storage import StorageManager
from core.profiles import ProfileManager
from learning.candidates import CandidateGenerator
from learning.approvals import ApprovalManager, Approval
from learning.training import Trainer
from core.reachy_driver import ReachyMiniDriver
from core.logging_utils import setup_logging
import logging

setup_logging(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_full_pipeline():
    """Test the complete learning pipeline"""
    
    print("\n" + "=" * 70)
    print("TESTING REACHY MIMIC DATA PIPELINE")
    print("=" * 70)
    
    # Initialize components
    storage = StorageManager(root=ROOT)
    profiles = ProfileManager(storage=storage)
    reachy = ReachyMiniDriver(enable_hardware=False)
    reachy.connect()
    generator = CandidateGenerator(storage=storage, reachy=reachy)
    approvals_mgr = ApprovalManager(storage=storage, profiles=profiles)
    trainer = Trainer(storage=storage)
    
    # Step 1: Create a test profile
    print("\n1Ô∏è‚É£  Creating test profile...")
    profile_id = profiles.create_profile(name="TestUser", consent_voice=True)
    print(f"   ‚úì Created profile: {profile_id[:8]}")
    
    # Step 2: Generate candidates (simulating video recording)
    print("\n2Ô∏è‚É£  Generating candidates...")
    print("   (In real use, reference_video_path and reference_audio_path")
    print("    would be actual files from webcam or upload)")
    
    takes = generator.generate_candidates(
        profile_id=profile_id,
        emotion="Happy",
        text="This is a test recording",
        voice_mode="imitate",
        comedian=1.0,
        n_candidates=3,
        source_type="live",
        reference_video_path=None,  # Would be a real video file
        reference_audio_path=None,  # Would be extracted audio
    )
    
    print(f"\n   ‚úì Generated {len(takes)} candidates")
    
    # Step 3: Check what was stored
    print("\n3Ô∏è‚É£  Verifying stored data...")
    for i, take in enumerate(takes):
        episode_dir = os.path.join(storage.paths.episodes_dir, take.episode_id)
        conditioning_path = os.path.join(episode_dir, "conditioning.json")
        
        if os.path.exists(conditioning_path):
            with open(conditioning_path, 'r') as f:
                cond = json.load(f)
            print(f"\n   Candidate {i}:")
            print(f"     Episode ID: {take.episode_id[:8]}")
            print(f"     Conditioning: {json.dumps(cond, indent=6)}")
            print(f"     Preview audio: {os.path.exists(take.preview_audio_path)}")
        else:
            print(f"   ‚ö†Ô∏è  Conditioning file missing for candidate {i}")
    
    # Step 4: Approve best candidate
    print("\n4Ô∏è‚É£  Approving best candidate...")
    episode_ids = [t.episode_id for t in takes]
    best_idx = 0
    
    approval = Approval(
        episode_id=takes[best_idx].episode_id,
        ranking=[best_idx, 1, 2],
        antenna_role="Eyebrows",
        notes="Test approval"
    )
    
    approvals_mgr.approve(
        profile_id=profile_id,
        episode_ids=episode_ids,
        approval=approval
    )
    print(f"   ‚úì Approved candidate {best_idx}")
    
    # Step 5: Check mood progress
    print("\n5Ô∏è‚É£  Checking mood progress...")
    progress = profiles.mood_progress_table(profile_id)
    print("   Mood statistics:")
    for row in progress:
        if row['approved'] > 0:
            print(f"     {row['mood']}: {row['approved']} approved")
    
    # Step 6: Update model (stub)
    print("\n6Ô∏è‚É£  Updating profile model...")
    result = trainer.update_profile_models(profile_id)
    print(f"   ‚úì Model version: {result['model_version']}")
    print(f"   ‚úì Total episodes: {result['episodes_total']}")
    print(f"   ‚úì Approved episodes: {result['episodes_approved']}")
    
    # Step 7: List all episodes
    print("\n7Ô∏è‚É£  Listing all episodes for this profile...")
    episodes = storage.list_episodes(profile_id, limit=10)
    print(f"   Found {len(episodes)} episodes:")
    for ep in episodes:
        approved_mark = "‚úì" if ep['approved'] else "‚óã"
        print(f"     [{approved_mark}] {ep['episode_id'][:8]} - {ep['emotion']} - {ep['text'][:30]}")
    
    # Summary
    print("\n" + "=" * 70)
    print("PIPELINE TEST COMPLETE")
    print("=" * 70)
    print("\nüìä Summary:")
    print(f"   - Profile created: {profile_id[:8]}")
    print(f"   - Candidates generated: {len(takes)}")
    print(f"   - Episodes approved: {result['episodes_approved']}")
    print(f"   - Model version: {result['model_version']}")
    
    print("\nüí° What this means:")
    print("   ‚úì Data pipeline is working")
    print("   ‚úì Reference paths ARE being stored in conditioning.json")
    print("   ‚úì Approvals ARE updating mood statistics")
    print("   ‚úì Episodes ARE being saved to database")
    
    print("\n‚ö†Ô∏è  What's NOT implemented yet (by design):")
    print("   ‚úó Actual voice learning from reference audio")
    print("   ‚úó Actual motion learning from reference video")
    print("   ‚úó Real ML model training")
    
    print("\nüîß Next steps to enable REAL learning:")
    print("   1. Replace placeholder audio with voice conversion model")
    print("   2. Add face/pose extraction from reference video")
    print("   3. Train motion model conditioned on extracted features")
    print("   4. Implement actual training loop in trainer.py")
    
    print("\n‚úÖ The scaffolding is ready - just plug in your ML models!")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    test_full_pipeline()

